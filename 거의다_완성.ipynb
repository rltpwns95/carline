{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb5775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "        masked_image = cv2.bitwise_and(img, mask)\n",
    "        return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=5):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]),\n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, a=0.8, b=1., c=0.):\n",
    "    return cv2.addWeighted(initial_img, a, img, b, c)\n",
    "\n",
    "cap = cv2.VideoCapture(\"Drive.mp4\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Apply image processing pipeline\n",
    "        gray = grayscale(frame)\n",
    "        blur = gaussian_blur(gray, 5)\n",
    "        edges = canny(blur, 50, 150)\n",
    "        imshape = frame.shape\n",
    "        vertices = np.array([[(0,imshape[0]),(450, 320), (490, 320), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "        masked_edges = region_of_interest(edges, vertices)\n",
    "        line_image = hough_lines(masked_edges, 2, np.pi/180, 15, 40, 20)\n",
    "        result = weighted_img(line_image, frame, 0.8, 1., 0.)\n",
    "        \n",
    "        # Write the processed frame to output video\n",
    "        out.write(result)\n",
    "        \n",
    "        # Display the result\n",
    "        cv2.imshow('result', result)\n",
    "        \n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a9bee",
   "metadata": {},
   "source": [
    "#### 영상 중간에 NoneType에러가 발생하여 영상이 멈춰버리는 현상이 생김."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e1649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_colors(image):\n",
    "    # Filter white pixels\n",
    "    lower_white = np.array([200, 200, 200])\n",
    "    upper_white = np.array([255, 255, 255])\n",
    "    white_mask = cv2.inRange(image, lower_white, upper_white)\n",
    "    white_image = cv2.bitwise_and(image, image, mask=white_mask)\n",
    "\n",
    "    # Filter yellow pixels\n",
    "    lower_yellow = np.array([180, 180, 0])\n",
    "    upper_yellow = np.array([255, 255, 180])\n",
    "    yellow_mask = cv2.inRange(image, lower_yellow, upper_yellow)\n",
    "    yellow_image = cv2.bitwise_and(image, image, mask=yellow_mask)\n",
    "\n",
    "    # Combine the two filtered images\n",
    "    image2 = cv2.addWeighted(white_image, 1., yellow_image, 1., 0)\n",
    "    return image2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa6b8c",
   "metadata": {},
   "source": [
    "#### 차선 중 흰선과 노란선을 인식하는 코드를 만들었다. 이중 lower와 upper를 이용해 색상의 범위를 잡아줘서\n",
    "#### 어느정도 어두워도 인식할 수 있게 만들어 보았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c8895",
   "metadata": {},
   "source": [
    "# 2차 완성코드  nonetype오류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456bea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=5):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]),\n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    return lines\n",
    "\n",
    "def filter_colors(image):\n",
    "    # Filter white pixels\n",
    "    lower_white = np.array([200, 200, 200])\n",
    "    upper_white = np.array([255, 255, 255])\n",
    "    white_mask = cv2.inRange(image, lower_white, upper_white)\n",
    "    white_image = cv2.bitwise_and(image, image, mask=white_mask)\n",
    "\n",
    "    # Filter yellow pixels\n",
    "    lower_yellow = np.array([180, 180, 0])\n",
    "    upper_yellow = np.array([255, 255, 180])\n",
    "    yellow_mask = cv2.inRange(image, lower_yellow, upper_yellow)\n",
    "    yellow_image = cv2.bitwise_and(image, image, mask=yellow_mask)\n",
    "\n",
    "    # Combine the two filtered images\n",
    "    image2 = cv2.addWeighted(white_image, 1., yellow_image, 1., 0)\n",
    "    return image2\n",
    "\n",
    "def process_image(image):\n",
    "    # Define vertices for the region of interest\n",
    "    imshape = image.shape\n",
    "    \n",
    "    vertices = np.array([[(0,imshape[0]),(450, 320), (490, 320), (imshape[1]-150,imshape[0])]], dtype=np.int32)\n",
    "\n",
    "    # Apply color filtering\n",
    "    filtered_image = filter_colors(image)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = grayscale(filtered_image)\n",
    "\n",
    "    # Apply Gaussian smoothing\n",
    "    blur = gaussian_blur(gray, kernel_size=5)\n",
    "\n",
    "    # Apply Canny edge detection\n",
    "    edges = canny(blur, low_threshold=50, high_threshold=150)\n",
    "    # Apply region of interest mask\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "\n",
    "    # Apply Hough transform to detect lines\n",
    "    lines = hough_lines(masked_edges, rho=1, theta=np.pi/180, threshold=20, min_line_len=20, max_line_gap=300)\n",
    "\n",
    "    # Draw lines on original image\n",
    "    line_image = np.zeros_like(image)\n",
    "    draw_lines(line_image, lines)\n",
    "    final_image = cv2.addWeighted(image, 0.8, line_image, 1, 0)\n",
    "\n",
    "    return final_image\n",
    "\n",
    "cap = cv2.VideoCapture(\"Drive.mp4\")\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        result = process_image(frame)\n",
    "        cv2.imshow('result', result)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c257d",
   "metadata": {},
   "source": [
    "#### 동영상 실행을 해보았고 나갈 때 까지 잡음도 어느 정도 잡아줘서 문제 없이 진행하던 중 영상 후반부에서 다시 TypeError: 'NoneType' object is not iterable 오류가 발생하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da6411",
   "metadata": {},
   "source": [
    "이 문제를 해결하기 위해서 검색해보면서 해결방법을 찾아봤었는데\n",
    "TypeError: 'NoneType' object is not iterable 오류는 객체의 타입이 None일 때, 반복 가능한(iterable) 객체로 사용하려 할 때 발생하는 에러입니다.\n",
    "\n",
    "주어진 코드에서 해당 에러가 발생하는 부분은 draw_lines 함수 내부의 for 반복문입니다. 해당 반복문에서 lines 변수가 None일 경우, for 반복문에서 이를 반복 가능한 객체로 사용하려 하기 때문에 에러가 발생합니다.\n",
    "\n",
    "이 경우, hough_lines 함수에서 cv2.HoughLinesP 함수의 반환값이 None일 수 있습니다. 따라서 hough_lines 함수에서 반환값이 None인 경우를 처리하는 로직을 추가해야 합니다. 반환값이 None인 경우에는 draw_lines 함수를 호출하지 않고 함수를 종료하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c733e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "        masked_image = cv2.bitwise_and(img, mask)\n",
    "        return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=5):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]),\n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, a=0.8, b=1., c=0.):\n",
    "    return cv2.addWeighted(initial_img, a, img, b, c)\n",
    "\n",
    "cap = cv2.VideoCapture(\"Drive.mp4\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output2.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Apply image processing pipeline\n",
    "        gray = grayscale(frame)\n",
    "        blur = gaussian_blur(gray, 5)\n",
    "        edges = canny(blur, 50, 150)\n",
    "        imshape = frame.shape\n",
    "        vertices = np.array([[(210, imshape[0]), (300, 300), (420, 300), (350, imshape[0])],\n",
    "                             [(550, imshape[0]), (640, 320), (660, 320), (700, imshape[0])]], dtype=np.int32)\n",
    "        #vertices = np.array([[(0,imshape[0]),(450, 320), (490, 320), (imshape[1],imshape[0])],\n",
    "                            #[(0,imshape[0]),(450, 320), (490, 320), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "        masked_edges = region_of_interest(edges, vertices)\n",
    "        line_image = hough_lines(masked_edges, 2, np.pi/180, 15, 40, 20)\n",
    "        result = weighted_img(line_image, frame, 0.8, 1., 0.)\n",
    "        \n",
    "        # Write the processed frame to output video\n",
    "        out.write(result)\n",
    "        \n",
    "        # Display the result\n",
    "        cv2.imshow('result', result)\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "정점 = np.array([[(150, imshape[0]), (300, 360), (420, 360), (imshape[1]-500, imshape[0])], [(600, imshape[ 0]), (480, 360), (550, 360), (imshape[1]-130, imshape[0])]], dtype=np.int32) 값을 얻지 못했을 때 실행 시 'NoneType' object is not iterable 오류가 발생하면 이유가 활성화됩니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec4bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd1bb7b5",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9326869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=5):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]),\n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    if lines is None:\n",
    "        return []\n",
    "    return lines\n",
    "def filter_colors(image):\n",
    "    # Filter white pixels\n",
    "    lower_white = np.array([200, 200, 200])\n",
    "    upper_white = np.array([255, 255, 255])\n",
    "    white_mask = cv2.inRange(image, lower_white, upper_white)\n",
    "    white_image = cv2.bitwise_and(image, image, mask=white_mask)\n",
    "\n",
    "    # Filter yellow pixels\n",
    "    lower_yellow = np.array([180, 180, 0])\n",
    "    upper_yellow = np.array([255, 255, 180])\n",
    "    yellow_mask = cv2.inRange(image, lower_yellow, upper_yellow)\n",
    "    yellow_image = cv2.bitwise_and(image, image, mask=yellow_mask)\n",
    "\n",
    "    # Combine the two filtered images\n",
    "    image2 = cv2.addWeighted(white_image, 1., yellow_image, 1., 0)\n",
    "    return image2\n",
    "\n",
    "def process_image(image):\n",
    "    # Define vertices for the region of interest\n",
    "    imshape = image.shape\n",
    "    \n",
    "    vertices = np.array([[(600,imshape[0]-280),\n",
    "                     (900,imshape[0]-450),\n",
    "                     (1100,imshape[0]-450),\n",
    "                     (1400, imshape[0]-280)]], dtype=np.int32)\n",
    "    #vertices = np.array([[(0,imshape[0]),(450, 320), (490, 320), (imshape[1]-150,imshape[0])]], dtype=np.int32)\n",
    "    #vertices = np.array([[(150, imshape[0]), (300, 360), (420, 360), (imshape[1]-500, imshape[0])],\n",
    "    #                         [(600, imshape[0]), (480, 360), (550, 360), (imshape[1]-130, imshape[0])]], dtype=np.int32)\n",
    "    # Apply color filtering\n",
    "    filtered_image = filter_colors(image)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = grayscale(filtered_image)\n",
    "\n",
    "    # Apply Gaussian smoothing\n",
    "    blur = gaussian_blur(gray, kernel_size=5)\n",
    "\n",
    "    # Apply Canny edge detection\n",
    "    edges = canny(blur, low_threshold=50, high_threshold=150)\n",
    "    # Apply region of interest mask\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "\n",
    "    # Apply Hough transform to detect lines\n",
    "    lines = hough_lines(masked_edges, rho=1, theta=np.pi/180, threshold=20, min_line_len=20, max_line_gap=300)\n",
    "\n",
    "    # Draw lines on original image\n",
    "    line_image = np.zeros_like(image)\n",
    "    draw_lines(line_image, lines)\n",
    "    final_image = cv2.addWeighted(image, 0.8, line_image, 1, 0)\n",
    "\n",
    "    return final_image\n",
    "\n",
    "cap = cv2.VideoCapture(\"MDR_221009_024928.AVI\")\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        result = process_image(frame)\n",
    "        cv2.imshow('result', result)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.imwrite('frame4.jpg', frame)\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7eaa03",
   "metadata": {},
   "source": [
    "환경 조건을 적용하려면, 먼저 어떤 환경 조건을 적용할지 결정해야 합니다. 예를 들어, 날씨가 흐릴 때 이미지 처리 파이프라인에서 사용하는 컬러 필터링이 제대로 작동하지 않을 수 있으므로, 다른 컬러 필터링 방법을 적용하는 것이 좋을 수 있습니다.\n",
    "\n",
    "이를 위해 filter_colors() 함수를 수정하여, 날씨 조건에 따라 적절한 필터링을 적용할 수 있습니다. 예를 들어, 날씨가 흐릴 때는 밝기 값이 작아질 수 있으므로, 밝기를 낮추는 등의 필터링 방법을 추가로 적용할 수 있습니다.\n",
    "\n",
    "또한, 이미지 처리 파이프라인 전체를 동적으로 재조정할 수도 있습니다. 예를 들어, 날씨 조건이 흐릴 때는 Canny edge detection에서 사용하는 low_threshold 값을 더 작게 조정하여 엣지 검출이 더 잘되도록 할 수 있습니다.\n",
    "\n",
    "이 외에도, 다양한 환경 조건에 따라 파이프라인을 동적으로 재조정하는 방법이 있을 수 있으니, 구체적인 환경 조건과 파이프라인 구조에 따라 적절한 조정을 진행하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8786f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_window_search(binary_warped, left_current, right_current):\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "\n",
    "    nwindows = 4\n",
    "    window_height = np.int(binary_warped.shape[0] / nwindows)\n",
    "    nonzero = binary_warped.nonzero()  # 선이 있는 부분의 인덱스만 저장 \n",
    "    nonzero_y = np.array(nonzero[0])  # 선이 있는 부분 y의 인덱스 값\n",
    "    nonzero_x = np.array(nonzero[1])  # 선이 있는 부분 x의 인덱스 값 \n",
    "    margin = 100\n",
    "    minpix = 50\n",
    "    left_lane = []\n",
    "    right_lane = []\n",
    "    color = [0, 255, 0]\n",
    "    thickness = 2\n",
    "\n",
    "    for w in range(nwindows):\n",
    "        win_y_low = binary_warped.shape[0] - (w + 1) * window_height  # window 윗부분\n",
    "        win_y_high = binary_warped.shape[0] - w * window_height  # window 아랫 부분\n",
    "        win_xleft_low = left_current - margin  # 왼쪽 window 왼쪽 위\n",
    "        win_xleft_high = left_current + margin  # 왼쪽 window 오른쪽 아래\n",
    "        win_xright_low = right_current - margin  # 오른쪽 window 왼쪽 위 \n",
    "        win_xright_high = right_current + margin  # 오른쪽 window 오른쪽 아래\n",
    "\n",
    "        cv2.rectangle(out_img, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), color, thickness)\n",
    "        cv2.rectangle(out_img, (win_xright_low, win_y_low), (win_xright_high, win_y_high), color, thickness)\n",
    "        good_left = ((nonzero_y >= win_y_low) & (nonzero_y < win_y_high) & (nonzero_x >= win_xleft_low) & (nonzero_x < win_xleft_high)).nonzero()[0]\n",
    "        good_right = ((nonzero_y >= win_y_low) & (nonzero_y < win_y_high) & (nonzero_x >= win_xright_low) & (nonzero_x < win_xright_high)).nonzero()[0]\n",
    "        left_lane.append(good_left)\n",
    "        right_lane.append(good_right)\n",
    "        # cv2.imshow(\"oo\", out_img)\n",
    "\n",
    "        if len(good_left) > minpix:\n",
    "            left_current = np.int(np.mean(nonzero_x[good_left]))\n",
    "        if len(good_right) > minpix:\n",
    "            right_current = np.int(np.mean(nonzero_x[good_right]))\n",
    "\n",
    "    left_lane = np.concatenate(left_lane)  # np.concatenate() -> array를 1차원으로 합침\n",
    "    right_lane = np.concatenate(right_lane)\n",
    "\n",
    "    leftx = nonzero_x[left_lane]\n",
    "    lefty = nonzero_y[left_lane]\n",
    "    rightx = nonzero_x[right_lane]\n",
    "    righty = nonzero_y[right_lane]\n",
    "\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    ploty = np.linspace(0, binary_warped.shape[0] - 1, binary_warped.shape[0])\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "\n",
    "    ltx = np.trunc(left_fitx)  # np.trunc() -> 소수점 부분을 버림\n",
    "    rtx = np.trunc(right_fitx)\n",
    "\n",
    "    out_img[nonzero_y[left_lane], nonzero_x[left_lane]] = [255, 0, 0]\n",
    "    out_img[nonzero_y[right_lane], nonzero_x[right_lane]] = [0, 0, 255]\n",
    "\n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color = 'yellow')\n",
    "    plt.plot(right_fitx, ploty, color = 'yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    plt.show()\n",
    "\n",
    "    ret = {'left_fitx' : ltx, 'right_fitx': rtx, 'ploty': ploty}\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4056deb",
   "metadata": {},
   "source": [
    "## 과제 1차-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416a5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "        masked_image = cv2.bitwise_and(img, mask)\n",
    "        return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=5):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]),\n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, a=0.8, b=1., c=0.):\n",
    "    return cv2.addWeighted(initial_img, a, img, b, c)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"MDR_221009_024928.AVI\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output2.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Apply image processing pipeline\n",
    "        gray = grayscale(frame)\n",
    "        blur = gaussian_blur(gray, 5)\n",
    "        edges = canny(blur, 50, 150)\n",
    "        imshape = frame.shape\n",
    "        vertices = np.array([[(600,imshape[0]-280),(900,imshape[0]-450),(1100,imshape[0]-450),(1400, imshape[0]-280)]], dtype=np.int32)\n",
    "        \n",
    "        vertices2 = np.array([[(600,imshape[0]-280),(900,imshape[0]-450),(950,imshape[0]-450),(800,imshape[0]-280)],\n",
    "                     [(1100,imshape[0]-280),(1050,imshape[0]-450),(1080,imshape[0]-450),(1250, imshape[0]-280)]], dtype=np.int32)\n",
    "        masked_edges = region_of_interest(edges, vertices2)\n",
    "        line_image = hough_lines(masked_edges, 2, np.pi/180, 15, 40, 20)\n",
    "        result = weighted_img(line_image, frame, 0.8, 1., 0.)\n",
    "        \n",
    "        # Write the processed frame to output video\n",
    "        out.write(result)\n",
    "        \n",
    "        # Display the result\n",
    "        cv2.imshow('result', result)\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88efc4b0",
   "metadata": {},
   "source": [
    "## 수정 1차----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf698c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "        masked_image = cv2.bitwise_and(img, mask)\n",
    "        return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[0, 255, 0], thickness=5):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]),\n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, a=0.8, b=1., c=0.):\n",
    "    return cv2.addWeighted(initial_img, a, img, b, c)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"MDR_221009_024928.AVI\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output2.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Apply image processing pipeline\n",
    "        gray = grayscale(frame)\n",
    "        blur = gaussian_blur(gray, 5)\n",
    "        edges = canny(blur, low_threshold=50, high_threshold=150)\n",
    "        imshape = frame.shape\n",
    "        vertices = np.array([[(600,imshape[0]-280),(900,imshape[0]-450),(1100,imshape[0]-450),(1400, imshape[0]-280)]], dtype=np.int32)\n",
    "        \n",
    "        vertices2 = np.array([[(600,imshape[0]-280),(900,imshape[0]-450),(950,imshape[0]-450),(800,imshape[0]-290)],\n",
    "                     [(1100,imshape[0]-280),(1050,imshape[0]-450),(1080,imshape[0]-450),(1250, imshape[0]-280)]], dtype=np.int32)\n",
    "        masked_edges = region_of_interest(edges, vertices2)\n",
    "        line_image = hough_lines(masked_edges, 2, np.pi/180, 15, 40, 20)\n",
    "        result = weighted_img(line_image, frame, 0.8, 1., 0.)\n",
    "        \n",
    "        # Write the processed frame to output video\n",
    "        out.write(result)\n",
    "        \n",
    "        # Display the result\n",
    "        cv2.imshow('result', result)\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9aece0",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2032b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=5):\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]),\n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, a=0.8, b=1., c=0.):\n",
    "    return cv2.addWeighted(initial_img, a, img, b, c)\n",
    "\n",
    "\n",
    "def select_white_yellow(img):\n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Define range of white color in HSV\n",
    "    lower_white = np.array([0, 0, 200], dtype=np.uint8)\n",
    "    upper_white = np.array([255, 30, 255], dtype=np.uint8)\n",
    "\n",
    "    # Define range of yellow color in HSV\n",
    "    lower_yellow = np.array([20, 100, 100], dtype=np.uint8)\n",
    "    upper_yellow = np.array([30, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    # Threshold the HSV image to get only white and yellow colors\n",
    "    mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
    "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "    mask = cv2.bitwise_or(mask_white, mask_yellow)\n",
    "    masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    return masked_img\n",
    "\n",
    "cap = cv2.VideoCapture(\"MDR_221009_024928.AVI\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output2.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Apply image processing pipeline\n",
    "        selected = select_white_yellow(frame)\n",
    "        gray = grayscale(selected)\n",
    "        blur = gaussian_blur(gray, 5)\n",
    "        edges = canny(blur, 50, 150)\n",
    "        imshape = frame.shape\n",
    "        vertices = np.array([[(600,imshape[0]-280),(900,imshape[0]-450),(1100,imshape[0]-450),(1400, imshape[0]-280)]], dtype=np.int32)\n",
    "        \n",
    "        vertices2 = np.array([[(600,imshape[0]-280),(900,imshape[0]-450),(950,imshape[0]-450),(800,imshape[0]-280)],\n",
    "                     [(1100,imshape[0]-280),(1050,imshape[0]-450),(1080,imshape[0]-450),(1250, imshape[0]-280)]], dtype=np.int32)\n",
    "        masked_edges = region_of_interest(edges, vertices2)\n",
    "        line_image = hough_lines(masked_edges, 2, np.pi/180, 15, 40, 20)\n",
    "        result = weighted_img(line_image, frame, 0.8, 1., 0.)\n",
    "        \n",
    "        # Write the processed frame to output video\n",
    "        out.write(result)\n",
    "        ㅂ\n",
    "        # Display the result\n",
    "        cv2.imshow('result', result)\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e626c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
